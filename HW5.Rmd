---
title: 'HW5: Team 12'
author: "Thomas Fleming, Blaire Li, Marc D. Ryser, Hengqian Zhang"
date: "Due March 10, 2016"
output:
html_notebook: default
html_document: default
pdf_document: default
---


```{r setup, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(warning = FALSE)
suppressMessages(library(ggplot2))
suppressMessages(library(dplyr))
suppressMessages(library(GGally))
library(BAS)
library(knitr)
# post on piazza for additional packages if there are wercker build errors due to missing packages
```

For this assignment we will explore simulation of data to compare methods for estimation and model selection.  To get started, refer to the code from Lab6 and simulate the datasets as described there.  Some "guideposts" for when to finish parts are provided within the problem set.

1.  Add to the Lab6 code a second set of 100 datasets for testing (prediction) with $25$ observations, but where the $X$'s have the same correlation matrix as in the training data.   Provide a brief description of the model that generated the data and summary of the simulation study.  (ie dimensions, true $\beta$ etc, number of simulated datasets etc.). _(Finish Monday: most code is from lab; modification fo add test data should be straightforward)_


ANSWER:
The true betas' we choose is the same as the betas' in lab6 which are {4,2,0,0,0,-1,0,1.5,0,0,0,1,0,0.5,0,0,0,0,-1,1,4}. We simulated 100 datasets and each with dimension 25 $\times$ 21. The procedure we use to generate the data is exactly the same as we did in lab 6. Considering the training data set, we wanted to simulate 100 datasets each with dimension  $75 \times  23$ (21 for beta plus Y and mu)
For each dataset, first we generated  $ 75 \times 10$ from standard normal distribution.

Secondly, we picked up the last 5 columns of the data we generated in step 1 and did matrix multiplication with {0.3,0.5,0.7,0.9,1.1} to get 75$\times$ 1 vector and  replicated it 5 times to get X1 with dimension 75 $\times$ 5

Thirdly, we generated 75 $\times$ 4 matrix from standard normal distribution and picked up the 4th column and added error from normal(0,0.1) to get X2 and X3 respectively.

Finally, we used cbind to combine X1, X2, X3 to get desired dataset and also computed Y and mu.

In addition, we can see the similar pattern in both correlation heatmap of training data and testing data. In simulation, there are 5 variables(columns) have correlation to each other. In heat map, there are ranctangles around the diagnal indicating the same patterns.
```{r}
set.seed(8675309)
# true parameters
sigma = 2.5
betatrue = c(4,2,0,0,0,-1,0,1.5, 0,0,0,1,0,.5,0,0,0,0,-1,1,4)
#          int|    X1                            | X2     |X3 

names(betatrue) = c("(Intercept)","x1","x2","x3","x4","x5",
                    "x6","x7","x8","x9","x10",
                    "x11","x12","x13","x14","x15",
                    "x16","x17","x18","x19","x20")

#sample size
n = 75

# part of dataframe name
fname=rep("df",100)

# create 100 datasets
for (i in 1:100) {
  
  # generate some standard normals
  Z = matrix(rnorm(n*10, 0, 1), ncol=10, nrow=n)
  
  #  Create X1 by taking linear cominations of Z to induce correlation among X1 components
  #multiplying first 5 columns by vector of numbers to create linear dependence
  X1 = cbind(Z, (Z[,1:5] %*% c(.3, .5, .7, .9, 1.1) %*% t(rep(1,5)) +
                   matrix(rnorm(n*5, 0, 1), ncol=5, nrow=n)))
  # generate X2 as a standard normal  
  #X2 independent, but correlated with X3
  X2 <- matrix(rnorm(n*4,0,1), ncol=4, nrow=n)
  
  # Generate X3 as a linear combination of X2 and noise  
  X3 <- X2[,4]+rnorm(n,0,sd=0.1)
  
  # combine them  
  X <- cbind(X1,X2,X3)
  
  # subtract off the column means
  X = sweep(X, 2, apply(X,2, mean)) 
  
  # Generate mu     
  # X does not have a column of ones for the intercept so need to add the intercept  
  # for true mu  
  mu = betatrue[1] + X %*% betatrue[-1] 
  
  # now generate Y  
  Y = mu + rnorm(n,0,sigma)  
  
  # make a dataframe and save it
  df = data.frame(Y, X, mu)
  colnames(df) = c("Y","x1","x2","x3","x4","x5",
                   "x6","x7","x8","x9","x10",
                   "x11","x12","x13","x14","x15",
                   "x16","x17","x18","x19","x20",
                   "mu")
  fname[i] = paste("df", as.character(i), sep="")
  save(df, file=fname[i])
}

load(fname[1])

par(mfrow = c(1,2))
#correlation map for training data 
image(cor(df[1:50,2:22]))
#correlation map for testing data 
image(cor(df[51:75,2:22]))
```


2.  Using Ordinary Least squares based on fitting the full model for each of the 100 data sets,  Compute the average RMSE for a) estimating $\beta^{true}$, b) estimating
$\mu^{true} = X \beta^{true}$ and c) out of sample prediction for the test data from the 100 data sets. Present histograms of the RMSEs and show where the average falls.
Note for a vector of length $d$, RMSE is defined as
$$
RMSE(\hat{\theta}) = \sqrt{\sum_{i = 1}^{d} (\hat{\theta}_j - \theta_j)^2/d}
$$
_(Finish Monday as this code from lab can be directly used/modified for this)_

```{r}
a<-c(0,0,1,1.0)
print(~a)

RMSE.beta  = rep(0,100)
RMSE.mu  = rep(0,100)
RMSE.test.pred  = rep(0,100)

ls = vector("list",100)

#Load simulation data frames and compute RMSE's
for( i in 1:100) {
  rm(df)
  load(fname[i])
  ls[[i]] = lm(Y ~ . -mu, data=df[1:50,])
  beta.ols = coef(ls[[i]])
  X.ols = model.matrix(Y ~ . -mu, data=df[1:50,])
  RMSE.beta[i] = sqrt(mean((betatrue - beta.ols)^2))
  RMSE.mu[i] = sqrt(mean((mu[1:50,] - X.ols %*% beta.ols)^2))
  RMSE.test.pred[i] = sqrt(mean((Y - predict(ls[[i]], newdata = df[51:75,]))^2))
}

#  average RMSE for estimating beta
avg.rmse.beta = mean(RMSE.beta)

#  average RMSE for estimating mu
avg.rmse.mu = mean(RMSE.mu)

# average RMSE for test set predictions
avg.rmse.test = mean(RMSE.test.pred)

#store average RMSE's in data frame
avg.rmse.df = data.frame(beta = avg.rmse.beta, mu = avg.rmse.mu, test = avg.rmse.test)

#Table for average RMSE's
kable(avg.rmse.df, caption = "Average RMSE's")

#store RSME's in data frame
rmse.df = data.frame(RMSE.beta, RMSE.mu, RMSE.test.pred)

#histogram: beta
ggplot(data = rmse.df[1], aes(x = rmse.df[1])) + theme_light() + labs(x = "RSME: Beta", y = "Frequency") + geom_histogram(fill = "lightblue", color = "darkblue") + geom_vline(xintercept = avg.rmse.beta, color = "red")

#histogram: mu
ggplot(data = rmse.df[2], aes(x = rmse.df[2])) + theme_light() + labs(x = "RMSE: Mu", y = "Frequency") + geom_histogram(fill = "khaki", color = "darkgoldenrod") + geom_vline(xintercept = avg.rmse.mu, color = "darkblue")

#histogram: test prediction
ggplot(data = rmse.df[3], aes(x = rmse.df[3])) + theme_light() + labs(x = "RMSE: Test Predictions", y = "Frequency") + geom_histogram(fill = "salmon", color = "orangered3") + geom_vline(xintercept = avg.rmse.test, color = "darkblue")
```


3.  Use AIC with either stepwise or all possible subsets to select a model and then use OLS to estimate the parameters under that model.  Using the estimates to compute the RMSE for a) estimating $\beta^{true}$, b) estimating $\mu^{true}$, and c) predicting $Y^{test}$. Present  histograms of the RMSE, and show where the  average RMSE falls on the plot.   Also report d) the number of times you select the true model using AIC out of the 100 simulations. _(A little more challenging: discuss with team  by Tuesday.  Figuring this out how to calculate RMSE with model selection will be needed for subsequent parts so start this early!.  Once this is done the  problem 5 should be easy!  Your write up should make it clear whether you used stepwise or all possible subsets)_ 

```{r}

#rmse function
rmse = function(y, ypred){
  rmse=sqrt(mean((y-ypred)^2))
  return(rmse)
}

#create vector with the same length and same name of betatrue
beta_like = numeric(length(betatrue))
names(beta_like) = names(betatrue)

beta_model = betatrue
beta_model[which(beta_model!=0)] = 1

#initialize RMSE vector
RMSE_beta_aic  = rep(0,100)
RMSE_mu_aic  = rep(0,100)
RMSE_test_aic  = rep(0,100)

count_true = 0
for(i in 1:100){
  rm(df)
  load(fname[i])
  #stepwise selection with AIC
  app_best = step(ls[[i]], k=2,trace=0)
  #create a copy of beta_like
  beta_e = beta_like
  #fill estimated beta with 0
  beta_e[names(app_best$coefficients)] = app_best$coefficients
  
  coe_position = beta_like
  coe_position[names(app_best$coefficients)] = 1
  if(all(coe_position == beta_model)){
    count_true = count_true+1
  }
  
  ## for beta
  RMSE_beta_aic[i] = rmse(betatrue,beta_e)
  ## for mu
  RMSE_mu_aic[i] = rmse(mu, app_best$fitted.values)
  ## for testing data
  RMSE_test_aic[i] = rmse(Y,predict(app_best, data = df[51:75,]))
}

#  average RMSE for estimating beta
avg_rmse_beta = mean(RMSE_beta_aic)

#  average RMSE for estimating mu
avg_rmse_mu = mean(RMSE_mu_aic)

# average RMSE for testing data
avg_rmse_test = mean(RMSE_test_aic)

#store RSME's in data frame
rmse_df_aic = data.frame(RMSE_beta_aic, RMSE_mu_aic, RMSE_test_aic)
#beta
ggplot(data = rmse_df_aic[1], aes(x = rmse_df_aic[1])) + 
  geom_histogram(fill = "lightblue", color = "darkblue")+
  geom_vline(xintercept = avg_rmse_beta, color = "red")
#mu
ggplot(data = rmse_df_aic[2], aes(x = rmse_df_aic[2])) + 
  geom_histogram(fill = "khaki", color = "darkgoldenrod")+
  geom_vline(xintercept = avg_rmse_mu, color = "darkblue")
#test
ggplot(data = rmse_df_aic[3], aes(x = rmse_df_aic[3])) + 
  geom_histogram(fill = "salmon", color = "orangered3")+
  geom_vline(xintercept = avg_rmse_test, color = "darkblue")


count_true
```


4.  Take a look at the summaries from the estimates under the best AIC model from the simulation that is equal to your team number.  Create confidence intervals for the $\beta$'s and comment on whether they include zero or not or the true value.
```{r}
app_best_12 = step(ls[[12]], k=2,trace=0)
summary(app_best_12)
confint(app_best_12)
```
5.   Use BIC with either stepwise or all possible subsets to select a model and then use OLS to estimate the parameters under that model.  Use the estimates to compute the RMSE for a) estimating $\beta^{true}$, b) $\mu^{true}$, and c) predicting $Y^{test}$. Present  histograms of the RMSE, and show where the average RMSE falls on the plot.   Also report d) the number of times you select the true model using BIC out of the 100 simulations. 
```{r}
#create vector with the same length and same name of betatrue
beta_like = numeric(length(betatrue))
names(beta_like) = names(betatrue)


beta_model = betatrue
beta_model[which(beta_model!=0)] = 1

#initialize RMSE vector
RMSE_beta_bic  = rep(0,100)
RMSE_mu_bic  = rep(0,100)
RMSE_test_bic  = rep(0,100)

for(i in 1:100){
  rm(df)
  load(fname[i])
  #stepwise selection with BIC
  app_best = step(ls[[i]], k=log(50),trace=0)
  #create a copy of beta_like
  beta_e = beta_like
  #fill estimated beta with 0
  beta_e[names(app_best$coefficients)] = app_best$coefficients
  
  coe_position = beta_like
  coe_position[names(app_best$coefficients)] = 1
  if(all(coe_position == beta_model)){
    count_true = count_true+1
  }
  
  
  ## for beta
  RMSE_beta_bic[i] = rmse(betatrue,beta_e)
  ## for mu
  RMSE_mu_bic[i] = rmse(mu, app_best$fitted.values)
  ## for testing data
  RMSE_test_bic[i] = rmse(Y,predict(app_best, data = df[51:75,]))
}

#  average RMSE for estimating beta
avg_rmse_beta = mean(RMSE_beta_bic)

#  average RMSE for estimating mu
avg_rmse_mu = mean(RMSE_mu_bic)

# average RMSE for testing data
avg_rmse_test = mean(RMSE_test_bic)

#store RSME's in data frame
rmse_df_bic = data.frame(RMSE_beta_bic, RMSE_mu_bic, RMSE_test_bic)
#beta
ggplot(data = rmse_df_bic[1], aes(x = rmse_df_bic[1])) + 
  geom_histogram(fill = "lightblue", color = "darkblue")+
  geom_vline(xintercept = avg_rmse_beta, color = "red")
#mu
ggplot(data = rmse_df_bic[2], aes(x = rmse_df_bic[2])) + 
  geom_histogram(fill = "khaki", color = "darkgoldenrod")+
  geom_vline(xintercept = avg_rmse_mu, color = "darkblue")
#test
ggplot(data = rmse_df_bic[3], aes(x = rmse_df_bic[3])) + 
  geom_histogram(fill = "salmon", color = "orangered3")+
  geom_vline(xintercept = avg_rmse_test, color = "darkblue")
count_true

```

6.  Take a look at the summaries from the estimates under the best BIC model from the simulation that is equal to your team number.  Create confidence intervals for the $\beta$'s and comment on whether they include zero or not or the true value.
```{r}
app_best_12 = step(ls[[12]], k=log(50),trace=0)
summary(app_best_12)
confint(app_best_12)
```
7. Theory (work individually and then combine to add group solution, try to complete by Wednesday before class)
For the linear model, assume that the $X$ have been centered so that they all have mean 0.  For the linear model
$$Y \sim N(1_n \beta_0 + X \beta, I_n/\phi)
$$
using Zellner's $g$-prior for  $\beta$ with 
$$\beta \mid \beta_0, \phi \sim N(0, g (X^TX)^{-1}/\phi)
$$
and the improper independent Jeffrey's prior $$p(\beta_0, \phi) \propto 1/\phi$$
find the a) posterior distriubtion of $\beta \mid Y, g, \phi$, b) posterior distribution of $\mu_i = x^T_i \beta \mid Y, g, \phi$ and c) the posterior predictive distribution of $Y^{test} \mid Y, g, \phi$ as functions of the OLS/MLE summaries. _(you may use results in notes - just quote - or derive)_

ANSWER: a)
$$ p(\beta | Y, g, \phi) \propto p(Y | \beta, g, \phi) p(\beta | g, \phi) $$

Since Y is independent of g and Zellner's g-prior for $\beta$ is actually independent of $\beta_{0}$, we can plug in the given distributions for Y and $\beta$:

$= N(1_{n}\beta_{0} + X\beta, I_{n}/\phi,) N(0, g(X^tX)^{-1}/\phi)$

$$\propto e^{-((y - (1_{n}\beta_{0} + X\beta))^T (I_{n}/\phi)^{-1} (y - (1_{n}\beta_{0} + X\beta)))/2 } e^{- \beta^t (g(X^TX)^{-1}/\phi)^{-1} \beta/2} $$

$$\propto e^{- \dfrac{1}{2\sigma^2}((y - (1_{n}\beta_{0} + X\beta))^T(y - (1_{n}\beta_{0} + X\beta))) } e^{- \dfrac{1}{2 \sigma^2} \beta^t(X^TX)/g \beta} $$

$$ \propto e^{- \dfrac{1}{2 \sigma^2} (y^T y - 2\beta^TX^Ty - \beta^TX^TX\beta - 2_n\beta_{0}^Ty + 1_{n}\beta_{0}1_{n}\beta_{0} + \beta^T((X^TX)/g)\beta) } = \beta^T A \beta - 2\beta B + C $$

where $$ A = \dfrac{(1 + g) X^T X}{g \sigma^2} $$, $$ B = \dfrac{X^T y}{\sigma^2} $$, and $$ c = c(y, \beta_{0}) $$

Since c is not a function of $\beta$, we can leave it out of the following proportion and rewrite the above in terms of A and B as,

$$ e^{- \dfrac{1}{2} (\beta^T A \beta - 2 \beta B)} $$

While completing the square in this situation is tedious, we can use knowledge of the strategy for the univariate normal, outlined on page 70 of Hoff, where it is easier to calculate the posterior mean and variance. It can be shown that the formulas for the posterior mean and variance also apply to the multivariate case, and so we know that the posterior mean is equal to $$ \dfrac{A}{B} $$ and the posterior variance is equal to $$ \dfrac{1}{A} $$. If we expand these equations out, using the right-hand side of equations A and B, and simplify, we find that we have a normal distribution with:


$$Var[\beta | Y, g, \phi] = \dfrac{g}{g + 1}\sigma^2(X^tX)^{-1}$$

$$E[\beta | Y, g, \phi] = \dfrac{g}{g + 1}(X^TX)^{-1}X^Ty $$



b) Since the model matrix does not vary, we can find the distribution for $$ \mu_{i} = x_{i}^t\beta | Y, g, \phi $$ by taking the expected value and variance of $$ \beta | Y, g, \phi $$:

$$ E[x_i\beta | Y, g, \phi] = x_iE[ \beta | Y, g, \phi]$$

$$ = x_i\dfrac{g}{g + 1}(X^TX)^{-1}X^Ty $$

$$ Var[x_i\beta | Y, g, \phi] = x_i^t x_i Var[\beta | Y, g, \phi]$$

$$ = x_i^t x_i \dfrac{g}{g + 1} \sigma^2(X^TX)^{-1} $$

*In the derivations below, the $\beta_{0}$, $\beta$, $\epsilon$, $X$, and $\sigma$ represent those associated with the test set. While we could have taken pains to label each of them "test", we have left this notation out for the sake of simplicity.

c) $$ E[Y^{test} | Y, g, \phi] = E[ 1_n \beta_{0} + X\beta + \epsilon^ | Y, g, \phi]$$

$$ = E[ 1_n \beta_{0} | Y, g, \phi] + E[X\beta | Y, g, \phi] + E[\epsilon^ | Y, g, \phi] $$

$$ = \dfrac{1}{\phi} + x_i \dfrac{g}{1 + g} (X^TX)^{-1}X^Ty + 0$$

$$ = \dfrac{1}{\phi} + x_i \dfrac{g}{1 + g} (X^TX)^{-1}X^Ty $$

$$Var[Y^{test} | Y, g, \phi] =  Var[ 1_n \beta_{0} + X\beta + \epsilon^ | Y, g, \phi] $$

$$ = Var[1_n \beta_{0} | Y, g, \phi] + Var[X \beta | Y, g, \phi] + Var[\epsilon^ | Y, g, \phi] $$

$$ = \dfrac{1}{n \phi} + \dfrac{g}{g + 1}\sigma^2(X^TX)^{-1} + \dfrac{I_n}{\phi}$$

$$ = \dfrac{1}{\phi} ( \dfrac{1}{n} + \dfrac{g}{g + 1}(X^TX)^{-1} + I_n) $$


8. What are the corresponding distributions in 7) unconditional on $\phi$?  (hint recall theorem from class)  Are $\beta_0$ and $\beta$ still independent?  Explain.

ANSWER:

$$ p(\beta | Y, g) = \int p(\beta | Y, g, \phi) p(\phi | Y, g) d\phi $$
$$ = \int (2\pi)^{-p/2} \begin{vmatrix}\dfrac{I_{n}}{\phi}\end{vmatrix}^{-1/2} exp(-\dfrac{(Y - (1_{n}\beta_{0} + X\beta))^T (I_{n}/\phi)^{-1} (Y - (1_{n}\beta_{0} + X\beta))}{2}) \dfrac{(\dfrac{\nu_{n}\hat{\sigma^2}}{2})}{\Gamma(\nu_{n}/2)}^{\nu_{n}/2} \phi^{\nu_{n}/2 - 1} exp(-\dfrac{\nu_{n}\hat{\sigma^2}}{2}) d\phi $$

$$ \propto \int \phi^{p/2} \phi^{\nu_{n}/2 -1} exp(-\dfrac{(Y - (1_{n}\beta_{0} + X\beta))^T (Y - (1_{n}\beta_{0} + X\beta))}{2}\phi) exp(-\dfrac{\nu_{n}\hat{\sigma^2}}{2}) d\phi $$

$$ \propto \int \phi^{(p+\nu_{n})/2 -1} exp(-\dfrac{(Y - (1_{n}\beta_{0} + X\beta))^T (Y - (1_{n}\beta_{0} + X\beta)) + \nu_{n}\hat{\sigma^2}}{2}\phi) d\phi $$ 

This is the kernel of a gamma and we know that it is equal to the reciprocal of its proportional constant:

$$  = \Gamma(\dfrac{p + \nu_{n}}{2}) \Big[\dfrac{(Y - (1_{n}\beta_{0} + X\beta))^T (Y - (1_{n}\beta_{0} + X\beta)) + \nu_{n}\hat{\sigma^2}}{2}\Big]^{-(p + \nu_{n})/2} \propto \Big[(Y - (1_{n}\beta_{0} + X\beta))^T (Y - (1_{n}\beta_{0} + X\beta)) + \nu_{n}\hat{\sigma^2}\Big]^{-(p + \nu_{n})/2} $$

$$ \propto \Big[1 + \dfrac{1}{\nu_{n}}\dfrac{(Y - (1_{n}\beta_{0} + X\beta))^T (Y - (1_{n}\beta_{0} + X\beta))}{\hat{\sigma^2}}\Big]^{-(p+\nu_{n})/2} $$

This is proportional to a Student-T distribution with $\nu_{n}$ degrees of freedom.

9. Let $\tau = 1/g$ and substitute that in the prior for $\beta$
$$\beta \mid \beta_0, \phi \sim N(0, (X^TX)^{-1}/(\tau \phi))
$$
If $\tau \sim G(1/2, n/2)$, show that the prior on $\beta$ is a Cauchy Distribution 
$$\beta \mid  \phi, \beta_0 \sim C(0,  (X^TX/n)^{-1}/\phi)$$
_(a Cauchy distribution is a Student t with 1 df - see notes for density)_

ANSWER:

$$p(\beta | \beta_{0}, \phi) = \int p(\beta | \beta_{0}, \phi, g)p(\tau | \phi, \beta_{0})p(\phi, \beta_{0}) d\tau $$

Since $\tau$ does not depend on $\phi$ or $\beta_{0}$, we can use the given unconditional distribution for $\tau$. Plugging in the distributions, we get:

$$ = \int (2\pi)^{-p/2} \begin{vmatrix}\dfrac{(X^TX)^{-1}}{\tau \phi}\end{vmatrix}^{-1/2} exp(-\dfrac{\beta^T(\dfrac{(X^TX)}{\tau\phi})^{-1}\beta}{2})  \dfrac{\dfrac{n}{2}^{1/2}}{\Gamma(\dfrac{1}{2})} \tau^{1/2 - 1} exp(-\dfrac{n}{2}\tau) \dfrac{1}{\phi} d\tau $$

Grouping terms, we get:

$$ \propto \int \tau^{(p + 1)/2 - 1} exp(-\dfrac{(n +(\beta^T\phi(X^TX)\beta))}{2} \tau) d\tau $$

It is easy to see that this is the kernel of a Gamma distribution with $a = \dfrac{n + 1}{2}$ and $b = \dfrac{n + (\beta^T\phi(X^TX)\beta)}{2} $ . For this expression to be equal to 1, the proportional constant would need to be $ \dfrac{(\dfrac{n + (\beta^T\phi(X^TX)\beta)}{2})^{(n+1)/2}}{\Gamma(\dfrac{n + 1}{2})} $. It can be shown that the reciprocal of this proportional constant is what the above proportion is equal to. In mathematical terms:

$$ = \Gamma(\dfrac{p + 1}{2}) \Big[(\dfrac{n +(\beta^T\phi(X^TX)\beta)}{2})^{-(p+1)/2}\Big] \propto (n +(\beta^T\phi(X^TX)\beta))^{-(p+1)/2} $$
$$ \propto \Big[1 + \dfrac{\beta^T\phi(X^TX)\beta}{n}\Big]^{-(p+1)/2}$$

So, the prior on $\beta$ is proportional to a student-T with one degree of freedom, which is also a Cauchy distribution.

_To speed up running time for the next set of problems, do the calculations for 9-13 in one named code chunk. then use separate code chunks to provide the necessary solutions for the different parts.  Test code using one or two simulated data sets, before running on all simulated data sets.  Once you are satisfied set cache=TRUE for the code chunk._

10.  Using Bayesian variable selection under the $g$-prior with $g = n$ and a uniform prior distribution over models,  find the highest posterior probability model (HPM)  using `bas.lm` from library `BAS` (or other software). (If you use `BAS`, please download `BAS` version 1.4.3 from CRAN).  Using the mean of the appropriate posterior distribution under the HPM, find the average RMSE for a) estimating $\beta^{true}$, b) estimating $\mu^{true}$ and c) predicting $Y^{test}$.  Plot histograms of the RMSE and add the average RMSE to the plots.   What proportion of the time did you select the true model?   Your answer should describe whether you used enumeration or MCMC, number of iterations or models, etc.  If you used MCMC, check diagnostic plots to examin convergence.  
Note `BAS` has functions to compute the fitted values `fitted` and predicted values `predict` for the HPM (see the vignette or help files), however, to find the posterior mean for the beta's for a given model, we need to extract the information from the object.  The following function can be use to do this. 



```{r}
coef.HPM = function(object) {
  best = which.max(object$postprobs)
  model = object$which[[best]]
  post.mean = object$mle[[best]]*object$shrinkage[best]
  return(list(HPM = model, betahat = post.mean))
}


library(BAS)
#create vector with the same length and same name of betatrue
beta_like = numeric(length(betatrue))
names(beta_like) = names(betatrue)


beta_model = betatrue
beta_model[which(beta_model!=0)] = 1

#initialize RMSE vector
RMSE_beta  = rep(0,100)
RMSE_mu  = rep(0,100)
RMSE_test  = rep(0,100)


df.bas = vector("list",100)
for(i in 1:100){
  rm(df)
  load(fname[i])
  df.bas[[i]] = bas.lm(Y ~.-mu, data=df[1:50,],
                    prior="g-prior", a=nrow(df[1:50,]), modelprior=uniform(),
                    method="MCMC", MCMC.iterations = 200000, thin = 20)
  #get the HPM model
  betas.bas = coef(df.bas[[i]], n.models=1)
  betahat=betas.bas$postmean
   
  #the fitted values
  muhat = fitted(df.bas[[i]], estimator="HPM")
  #the predicted values
  pred.df = predict(df.bas[[i]], df[51:75,], estimator="HPM")
  predvalues = pred.df$fit
  
  #count how many times choose the true model
  coe_position = beta_like
  coe_position[which(betas.bas$postmean != 0)] = 1
  if(all(coe_position == beta_model)){
    count_true = count_true+1
  }
  
  
  ## for beta
  RMSE_beta[i] = rmse(betatrue,betahat)
  ## for mu
  RMSE_mu[i] = rmse(mu, muhat) 
  ## for testing data
  RMSE_test[i] = rmse(Y,predvalues)    
}

```

```{r}
 #  average RMSE for estimating beta
avg_rmse_beta = mean(RMSE_beta)

#  average RMSE for estimating mu
avg_rmse_mu = mean(RMSE_mu)

# average RMSE for testing data
avg_rmse_test = mean(RMSE_test)

#store RSME's in data frame
rmse_df_bas = data.frame(RMSE_beta, RMSE_mu, RMSE_test)
#beta
ggplot(data = rmse_df_bas[1], aes(x = rmse_df_bas[1])) + 
  geom_histogram(fill = "lightblue", color = "darkblue")+
  geom_vline(xintercept = avg_rmse_beta, color = "red")
#mu
ggplot(data = rmse_df_bas[2], aes(x = rmse_df_bas[2])) + 
  geom_histogram(fill = "khaki", color = "darkgoldenrod")+
  geom_vline(xintercept = avg_rmse_mu, color = "darkblue")
#test
ggplot(data = rmse_df_bas[3], aes(x = rmse_df_bas[3])) + 
  geom_histogram(fill = "salmon", color = "orangered3")+
  geom_vline(xintercept = avg_rmse_test, color = "darkblue")
count_true


#diagnostic plots for MCMC convergence
diagnostics(df.bas[[12]], type="pip")

```



(Look at before Wednesday to be prepared to ask any questions)

11.  Using the simulation that is equal to your team numbers, provide posterior summaries of the coefficient's of the HPM, such as Bayesian Confidence intervals.  
Comment on whether the intervals contain the true value or zero.

```{r}
betas.bas = coef(df.bas[[12]],n.models = 1) 
betas.bas
confint(betas.bas)

```


12.  To incorporate model uncertainty we could use  Bayesian Model Averaging, rather than the highest probability model. Repeat 10 and 11 using BMA for estimating the quantities.  

```{r}

```


13.  If we wanted to select the model that is "closest" to BMA,  we could use the model whose predictions are closest to BMA  using squared error loss.  We can find the best predictive model `BPM` from `BAS` using the predict function with `estimator="BPM"`.   Repeat 10 and 11 using the Best Predictive Model, `BPM`.


14.  Are the Bayesian estimates sensitive to the choice of prior?  Try 10-13 using the Zellner-Siow Cauchy prior (option `prior = "ZS-null"` in `bas.lm`)  


15.  Provide a summary of your simulation findings, with a table for the RMSEs for the different methods and parameters of interest $\beta$, $\mu$, $Y^{test}$ and proportion of time true model was selected.
Does any one method seem to do better than the others or are some methods better for one estimation/prediction problem than the others?  Explain.
For the energetic team - what about coverage?







